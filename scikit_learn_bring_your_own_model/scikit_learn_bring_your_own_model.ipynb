{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Amazon SageMaker scikit-learn Bring Your Own Model\n",
    "_**Hosting a pre-trained scikit-learn Model in Amazon SageMaker scikit-learn Container**_\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "Amazon SageMaker includes functionality to support a hosted notebook environment, distributed, serverless training, and real-time hosting. We think it works best when all three of these services are used together, but they can also be used independently.  Some use cases may only require hosting.  Maybe the model was trained prior to Amazon SageMaker existing, in a different service.\n",
    "\n",
    "This notebook shows how to use a pre-trained scikit-learn model with the Amazon SageMaker scikit-learn container to quickly create a hosted endpoint for that model.\n",
    "We use the California Housing dataset, present in Scikit-Learn: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html. The California Housing dataset was originally published in:\n",
    "\n",
    "> Pace, R. Kelley, and Ronald Barry. \"Sparse spatial auto-regressions.\" Statistics & Probability Letters 33.3 (1997): 291-297.\n",
    "\n",
    "---\n",
    "## Setup\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "* AWS region.\n",
    "* The IAM role arn used to give learning and hosting access to your data.\n",
    "* The S3 bucket that you want to use for training and model data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = \"sagemaker/DEMO-sklearn-byo-model\"\n",
    "\n",
    "print(f\"bucket: {bucket}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare data for model inference\n",
    "\n",
    "We load the California housing dataset from sklearn, and will use it to invoke SageMaker Endpoint"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = fetch_california_housing()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.data, data.target, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# we don't train a model, so we will need only the testing data\n",
    "testX = pd.DataFrame(X_test, columns=data.feature_names)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "testX.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download a pre-trained model file\n",
    "\n",
    "Download a pretrained Scikit-Learn Random Forest model.\n",
    "\n",
    "We used the California Housing dataset, present in Scikit-Learn: https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset to train the model.\n",
    "\n",
    "For more details on how to train the model with Amazon SageMaker, please refer to the [Develop, Train, Optimize and Deploy Scikit-Learn Random Forest notebook](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/scikit_learn_randomforest/Sklearn_on_SageMaker_end2end.ipynb)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!aws s3 cp s3://aws-ml-blog/artifacts/scikit_learn_bring_your_own_model/model.joblib ."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compressed the model file to a GZIP tar archive \n",
    "\n",
    "Note that the model file name must satisfy the regular expression pattern: `^[a-zA-Z0-9](-*[a-zA-Z0-9])*;`. The model file needs to be tar-zipped. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_file_name = \"model.joblib\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!tar czvf model.tar.gz $model_file_name"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Upload the pre-trained model `model.tar.gz` file to S3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fObj = open(\"model.tar.gz\", \"rb\")\n",
    "key = os.path.join(prefix, \"model.tar.gz\")\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(key).upload_fileobj(fObj)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set up hosting for the model\n",
    "\n",
    "This involves creating a SageMaker model from the model file previously uploaded to S3."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_data = \"s3://{}/{}\".format(bucket, key)\n",
    "print(f\"model data: {model_data}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Write the Inference Script\n",
    "\n",
    "When using endpoints with the Amazon SageMaker managed `Scikit Learn` container, we need to provide an entry point script for inference that will **at least** load the saved model.\n",
    "\n",
    "After the SageMaker model server has loaded your model by calling `model_fn`, SageMaker will serve your model. Model serving is the process of responding to inference requests, received by SageMaker `InvokeEndpoint` API calls.\n",
    "\n",
    "\n",
    "We will implement also the `predict_fn()` function that takes the deserialized request object and performs inference against the loaded model.\n",
    "\n",
    "We will now create this script and call it `inference.py` and store it at the root of a directory called `code`.\n",
    "\n",
    "**Note:** You would modify the script below to implement your own inferencing logic.\n",
    "\n",
    "Additional information on model loading and model serving for scikit-learn on SageMaker can be found in the [SageMaker Scikit-learn Model Server documentation](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html#deploy-a-scikit-learn-model)\n",
    "\n",
    "There are also several functions for hosting which we won't define,\n",
    " - `input_fn()` - Takes request data and deserializes the data into an object for prediction.\n",
    " - `output_fn()` - Takes the result of prediction and serializes this according to the response content type.\n",
    "\n",
    "These will take on their default values as described [SageMaker Scikit-learn Serve a Model documentation](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html#serve-a-model)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pygmentize ./code/inference.py"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Installing additional Python dependencies\n",
    "\n",
    "It also may be necessary to supply a `requirements.txt` file to ensure any necessary dependencies are installed in the container along with the script. For this script, in addition to the Python standard libraries, we showcase how to install the `boto3` `requests`, and `nltk` libraries."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pygmentize ./code/requirements.txt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deploy with Python SDK\n",
    "\n",
    "Here we showcase the process of creating a model from s3 artifacts, that could be used to deploy a model that was trained in a different session or even out of SageMaker."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = SKLearnModel(\n",
    "    role=role,\n",
    "    model_data=model_data,\n",
    "    framework_version=\"0.23-1\",\n",
    "    py_version=\"py3\",\n",
    "    source_dir=\"code\",\n",
    "    entry_point=\"inference.py\",\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create endpoint\n",
    "Lastly, you create the endpoint that serves up the model, through specifying the name and configuration defined above. The end result is an endpoint that can be validated and incorporated into production applications. This takes 5-10 minutes to complete."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time\n",
    "\n",
    "predictor = model.deploy(instance_type=\"ml.t2.medium\", initial_instance_count=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validate the model for use\n",
    "Now you can obtain the endpoint from the client library using the result from previous operations and generate classifications from the model using that endpoint."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Invoke with the Python SDK"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's generate the prediction for a single data point. We'll pick one from the test data generated earlier."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# the SKLearnPredictor does the serialization from pandas for us\n",
    "predictions = predictor.predict(testX[data.feature_names])\n",
    "print(predictions)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Alternative: invoke with `boto3`\n",
    "\n",
    "This is useful when invoking the model from external clients, e.g. Lambda Functions, or other micro-services."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "runtime = boto3.client(\"sagemaker-runtime\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Option 1: `csv` serialization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# csv serialization\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=predictor.endpoint,\n",
    "    Body=testX[data.feature_names].to_csv(header=False, index=False).encode(\"utf-8\"),\n",
    "    ContentType=\"text/csv\",\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Option 2: `npy` serialization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# npy serialization\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "# Serialise numpy ndarray as bytes\n",
    "buffer = BytesIO()\n",
    "# Assuming testX is a data frame\n",
    "np.save(buffer, testX[data.feature_names].values)\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=predictor.endpoint, Body=buffer.getvalue(), ContentType=\"application/x-npy\"\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (Optional) Delete the Endpoint\n",
    "\n",
    "If you're ready to be done with this notebook, please run the delete_endpoint line in the cell below.  This will remove the hosted endpoint you created and avoid any charges from a stray instance being left on."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predictor.delete_endpoint()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optional - Deploy a model from `SageMaker Model Registry` and update an existing SageMaker Endpoint"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Upload `sourcedir.tar.gz` to S3\n",
    "\n",
    "When using the SageMaker Python SDK, it will upload the files in `entry_point`, `source_dir`, and dependencies to S3 as a compressed `sourcedir.tar.gz` file \n",
    "\n",
    "Because you are deploying a model you trained outside of SageMaker with `boto3`, this is something you will have to do."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!cd code && tar czvf ../sourcedir.tar.gz *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fObj = open(\"sourcedir.tar.gz\", \"rb\")\n",
    "key = os.path.join(prefix, \"sourcedir.tar.gz\")\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(key).upload_fileobj(fObj)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sourcedir_data = \"s3://{}/{}\".format(bucket, key)\n",
    "print(f\"sources data: {sourcedir_data}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's inspect the content of this bucket"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!aws s3 ls s3://{bucket}/{prefix}/"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create a Model Group\n",
    "\n",
    "This will create a model group. A model group contains a group of model versions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "client = boto3.client(\"sagemaker\")\n",
    "\n",
    "model_package_group_name = \"sklearn-california-housing-\" + str(round(time.time()))\n",
    "model_package_group_input_dict = {\n",
    " \"ModelPackageGroupName\" : model_package_group_name,\n",
    " \"ModelPackageGroupDescription\" : \"My sample sklearn model package group\"\n",
    "}\n",
    "\n",
    "create_model_pacakge_group_response = client.create_model_package_group(**model_package_group_input_dict)\n",
    "print('ModelPackageGroup Arn : {}'.format(create_model_pacakge_group_response['ModelPackageGroupArn']))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Register a Model Version for the 1st model\n",
    "\n",
    "You will create a model package that you will use to create a SageMaker versioned model that is part of a model group.\n",
    "\n",
    "Nw create create a model package by specifying a Docker container that contains your inference code and the Amazon S3 location of your model artifacts, provide values for `InferenceSpecification`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "training_image = \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3\"\n",
    "sagemaker_program = \"inference.py\"\n",
    "\n",
    "modelpackage_inference_specification =  {\n",
    "    \"InferenceSpecification\": {\n",
    "      \"Containers\": [\n",
    "         {\n",
    "            \"Image\": training_image,\n",
    "             \"Environment\": {\n",
    "                \"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"20\",\n",
    "                \"SAGEMAKER_PROGRAM\": sagemaker_program,\n",
    "                \"SAGEMAKER_REGION\": region,\n",
    "                \"SAGEMAKER_SUBMIT_DIRECTORY\": sourcedir_data\n",
    "             },\n",
    "         }\n",
    "      ],\n",
    "      \"SupportedContentTypes\": [ \"text/csv\" ],\n",
    "      \"SupportedResponseMIMETypes\": [ \"text/csv\" ],\n",
    "   }\n",
    " }\n",
    "\n",
    "# Specify the model data\n",
    "modelpackage_inference_specification[\"InferenceSpecification\"][\"Containers\"][0][\"ModelDataUrl\"]=model_data\n",
    "\n",
    "create_model_package_input_dict = {\n",
    "    \"ModelPackageGroupName\" : model_package_group_name,\n",
    "    \"ModelPackageDescription\" : \"Model to predict California housing values\",\n",
    "    \"ModelApprovalStatus\" : \"PendingManualApproval\"\n",
    "}\n",
    "create_model_package_input_dict.update(modelpackage_inference_specification)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "create_mode_package_response = client.create_model_package(**create_model_package_input_dict)\n",
    "model_package_arn = create_mode_package_response[\"ModelPackageArn\"]\n",
    "print('ModelPackage Version ARN : {}'.format(model_package_arn))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## View Model Groups and Versions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "list_model_packages_response = client.list_model_packages(ModelPackageGroupName=model_package_group_name)\n",
    "list_model_packages_response"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You should now see model package version 1 in the `model package` ARN."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_version_arn = list_model_packages_response['ModelPackageSummaryList'][0]['ModelPackageArn']\n",
    "print(model_version_arn)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## View 1st Model Version Details"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "client.describe_model_package(ModelPackageName=model_version_arn)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Update 1st Model Approval Status"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_package_update_input_dict = {\n",
    "    \"ModelPackageArn\" : model_package_arn,\n",
    "    \"ModelApprovalStatus\" : \"Approved\"\n",
    "}\n",
    "model_package_update_response = client.update_model_package(**model_package_update_input_dict)\n",
    "model_package_update_response"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deploy the 1st Model in the Registry"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_1_name = 'DEMO-sklearn-califonia-housing-model-1-' + datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "print(\"Model name : {}\".format(model_1_name))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "primary_container = {\n",
    "    'ModelPackageName': model_version_arn,\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create `Model` "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "create_model_respose = client.create_model(\n",
    "    ModelName = model_1_name,\n",
    "    ExecutionRoleArn = get_execution_role(),\n",
    "    PrimaryContainer = primary_container\n",
    ")\n",
    "\n",
    "print(\"Model arn : {}\".format(create_model_respose[\"ModelArn\"]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create an Endpoint Config from 1st model\n",
    "\n",
    "This will create an endpoint configuration that Amazon SageMaker hosting services uses to deploy models. In the configuration, you identify one or more models, created using the `CreateModel` API, to deploy and the resources that you want Amazon SageMaker to provision. Then you call the `CreateEndpoint` API.\n",
    "\n",
    "More info on `create_endpoint_config` can be found on the [Boto3 SageMaker documentation page](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_endpoint_config)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "endpoint_config_1_name = \"sklearn-endpoint-config-1-\" + datetime.datetime.now().strftime(\n",
    "    \"%Y-%m-%d-%H-%M-%S\"\n",
    ")\n",
    "\n",
    "endpoint_config_1_response = client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_1_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"AllTrafficVariant\",\n",
    "            \"ModelName\": model_1_name,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"InstanceType\": \"ml.c5.large\",\n",
    "            \"InitialVariantWeight\": 1,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "endpoint_config_1_response"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deploy the 1st Endpoint Config to a real-time endpoint\n",
    "\n",
    "This will create an endpoint using the endpoint configuration specified in the request. Amazon SageMaker uses the endpoint to provision resources and deploy models. Note that you have already created the endpoint configuration with the `CreateEndpointConfig` API in the previous step.\n",
    "\n",
    "More info on `create_endpoint` can be found on the [Boto3 SageMaker documentation page](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_endpoint)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "endpoint_name = \"sklearn-endpoint-\" + datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "create_endpoint_response = client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_1_name,\n",
    ")\n",
    "\n",
    "create_endpoint_response"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wait for Endpoint to be ready"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "while describe_endpoint_response[\"EndpointStatus\"] == \"Creating\":\n",
    "    describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(describe_endpoint_response[\"EndpointStatus\"])\n",
    "    time.sleep(15)\n",
    "\n",
    "describe_endpoint_response"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Invoke Endpoint with `boto3`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# csv serialization\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=testX[data.feature_names].to_csv(header=False, index=False).encode(\"utf-8\"),\n",
    "    ContentType=\"text/csv\",\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Register a Model Version for the 2nd model\n",
    "\n",
    "You will now register a Model Version for the 2nd model in `Model Registry`. \n",
    "\n",
    "In real life, you will use a new trained model artifacts. In this notebook, you will use the same artifcats of the 1st model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "modelpackage_inference_specification =  {\n",
    "    \"InferenceSpecification\": {\n",
    "      \"Containers\": [\n",
    "         {\n",
    "            \"Image\": training_image,\n",
    "             \"Environment\": {\n",
    "                \"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"20\",\n",
    "                \"SAGEMAKER_PROGRAM\": sagemaker_program,\n",
    "                \"SAGEMAKER_REGION\": region,\n",
    "                \"SAGEMAKER_SUBMIT_DIRECTORY\": sourcedir_data\n",
    "             },\n",
    "         }\n",
    "      ],\n",
    "      \"SupportedContentTypes\": [ \"text/csv\" ],\n",
    "      \"SupportedResponseMIMETypes\": [ \"text/csv\" ],\n",
    "   }\n",
    " }\n",
    "\n",
    "# Specify the model data\n",
    "modelpackage_inference_specification[\"InferenceSpecification\"][\"Containers\"][0][\"ModelDataUrl\"]=model_data\n",
    "\n",
    "create_model_package_input_dict = {\n",
    "    \"ModelPackageGroupName\" : model_package_group_name,\n",
    "    \"ModelPackageDescription\" : \"Model to predict California housing values\",\n",
    "    \"ModelApprovalStatus\" : \"PendingManualApproval\"\n",
    "}\n",
    "create_model_package_input_dict.update(modelpackage_inference_specification)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You should now see model package version 2 in the `model package` ARN."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "create_mode_package_response = client.create_model_package(**create_model_package_input_dict)\n",
    "model_package_arn = create_mode_package_response[\"ModelPackageArn\"]\n",
    "print('ModelPackage Version ARN : {}'.format(model_package_arn))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## View Model Groups and Versions\n",
    "\n",
    "You should see there are two models registered - `/1` and `/2`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "list_model_packages_response = client.list_model_packages(ModelPackageGroupName=model_package_group_name)\n",
    "list_model_packages_response"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_version_arn = list_model_packages_response['ModelPackageSummaryList'][0]['ModelPackageArn']\n",
    "print(model_version_arn)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## View 2nd Model Version Details"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "client.describe_model_package(ModelPackageName=model_version_arn)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Update the 2nd Model Approval Status"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_package_update_input_dict = {\n",
    "    \"ModelPackageArn\" : model_package_arn,\n",
    "    \"ModelApprovalStatus\" : \"Approved\"\n",
    "}\n",
    "model_package_update_response = client.update_model_package(**model_package_update_input_dict)\n",
    "model_package_update_response"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deploy the 2nd Model in the Registry"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_2_name = 'DEMO-sklearn-califonia-housing-model-2-' + datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "print(\"Model name : {}\".format(model_1_name))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "primary_container = {\n",
    "    'ModelPackageName': model_version_arn,\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "create_model_respose = client.create_model(\n",
    "    ModelName = model_2_name,\n",
    "    ExecutionRoleArn = get_execution_role(),\n",
    "    PrimaryContainer = primary_container\n",
    ")\n",
    "\n",
    "print(\"Model arn : {}\".format(create_model_respose[\"ModelArn\"]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "endpoint_config_2_name = \"sklearn-endpoint-config-2-\" + datetime.datetime.now().strftime(\n",
    "    \"%Y-%m-%d-%H-%M-%S\"\n",
    ")\n",
    "\n",
    "endpoint_config_2_response = client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_2_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"AllTrafficVariant\",\n",
    "            \"ModelName\": model_2_name,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"InstanceType\": \"ml.c5.large\",\n",
    "            \"InitialVariantWeight\": 1,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "endpoint_config_2_response"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Update the real-time endpoint with the 2nd Endpoint Config\n",
    "\n",
    "This will deploy the new `EndpointConfig` specified in the request, switches to using newly created endpoint, and then deletes resources provisioned for the endpoint using the previous `EndpointConfig` (there is no availability loss).\n",
    "\n",
    "More info on `update_endpoint` can be found on the [Boto3 SageMaker documentation page](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.update_endpoint)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "update_endpoint_response = client.update_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_2_name\n",
    ")\n",
    "\n",
    "update_endpoint_response"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wait for Endpoint to be ready\n",
    "\n",
    "Navigating to the SageMaker Endpoints, in `SageMaker Components and registries` tab, you'll see the endpoint in `Updating` status."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "while describe_endpoint_response[\"EndpointStatus\"] == \"Updating\":\n",
    "    describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(describe_endpoint_response[\"EndpointStatus\"])\n",
    "    time.sleep(15)\n",
    "\n",
    "describe_endpoint_response"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Invoke Endpoint with `boto3`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# csv serialization\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=testX[data.feature_names].to_csv(header=False, index=False).encode(\"utf-8\"),\n",
    "    ContentType=\"text/csv\",\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## View `Model Registry` in SageMaker Studio\n",
    "\n",
    "![](img/sm_studio_model_registry.png \"View Model Registry in SageMaker Studio\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clean up\n",
    "\n",
    "Endpoints should be deleted when no longer in use, since (per the [SageMaker pricing page](https://aws.amazon.com/sagemaker/pricing/)) they're billed by time deployed."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "client.delete_endpoint(EndpointName=endpoint_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 5
}